# Automate Data Capture at Scale with Document AI: Challenge Lab

## Task 1. Enable the Cloud Document AI API and copy lab source files.

1. From the Navigation menu (Navigation menu icon), click APIs & services > Library.
2. Search for Cloud Document AI API, then click the Enable button to use the API in your Google Cloud project.
3. Sử dụng Cloud Shell

```
  mkdir ./document-ai-challenge
  gsutil -m cp -r gs://spls/gsp367/* \
    ~/document-ai-challenge/
```

## Task 2. Create a form processor

[xem guide ở đây](https://www.cloudskillsboost.google/course_templates/674/labs/586881)

### Create a processor

1. In the console, from the Navigation menu (Navigation menu icon), click Document AI > Overview.
2. Click Explore processors.
3. Click Create Processor for Form Parser, which is a type of general processor.
4. Specify the processor name as form-parser and select the region US (United States) from the list.
5. Click Create to create the general form-parser processor.
   This will create the processor and return to the processor details page that will display the processor ID, status, and the prediction endpoint.
6. Make a note of the Processor ID as you will use it with curl to make a POST call to the API in a later task.

## Task 3. Create Google Cloud resources

### Create input, output, and archive Cloud Storage buckets

```
export PROJECT_ID=$(gcloud config get-value core/project)
export INPUT_BUCKET_NAME=
export INPUT_BUCKET_LOCATION=
export OUTPUT_BUCKET_NAME=
export OUTPUT_BUCKET_LOCATION=
export ARCHIVE_BUCKET_NAME=
export ARCHIVE_BUCKET_LOCATION=

gsutil mb -c standard -l ${INPUT_BUCKET_LOCATION} -b on gs://${INPUT_BUCKET_NAME}
gsutil mb -c standard -l ${OUTPUT_BUCKET_LOCATION} -b on gs://${OUTPUT_BUCKET_NAME}
gsutil mb -c standard -l ${ARCHIVE_BUCKET_LOCATION} -b on gs://${ARCHIVE_BUCKET_LOCATION}
```

### Create a BigQuery dataset and tables

```
bq --location="US" mk  -d \
    --description "Form Parser Results" \
    ${PROJECT_ID}:invoice_parser_results

cd ~/document-ai-challenge/scripts/table-schema/

bq mk --table \
  invoice_parser_results.doc_ai_extracted_entities \
  doc_ai_extracted_entities.json
```

## Task 4. Deploy the document processing Cloud Run functions

1. Navigate to `scripts` directory:

```
cd ~/document-ai-challenge/scripts
```

2. Assign the Artifact Registry Reader role to the Compute Engine service account:

```
PROJECT_ID=$(gcloud config get-value project)
PROJECT_NUMBER=$(gcloud projects list --filter="project_id:$PROJECT_ID" --format='value(project_number)')

SERVICE_ACCOUNT=$(gcloud storage service-agent --project=$PROJECT_ID)

gcloud projects add-iam-policy-binding $PROJECT_ID \
  --member serviceAccount:$SERVICE_ACCOUNT \
  --role roles/pubsub.publisher
```

3. Deploy the Cloud Run functions:

```
# doi lai region
export CLOUD_FUNCTION_LOCATION="REGION"
export TRIGGER_INPUT_BUCKET_NAME=gs://... (lấy ở bucket ták 3)

gcloud functions deploy process-invoices \
--gen2 \
--region=${CLOUD_FUNCTION_LOCATION} \
--entry-point=process_invoice \
--runtime=python39 \
--service-account=${PROJECT_ID}@appspot.gserviceaccount.com \
--source=cloud-functions/process-invoices \
--timeout=400 \
--env-vars-file=cloud-functions/process-invoices/.env.yaml \
--trigger-resource=$TRIGGER_INPUT_BUCKET_NAME \
--trigger-event=google.storage.object.finalize\
--service-account $PROJECT_NUMBER-compute@developer.gserviceaccount.com \
--allow-unauthenticated
```

4. Chỉnh sửa các biến môi trường phù hợp: tham khảo [task 6](https://www.cloudskillsboost.google/course_templates/674/labs/586883)

## Task 5. Test and validate the end-to-end solution

```
gsutil -m cp -r ~/document-ai-challenge/invoices/* $TRIGGER_INPUT_BUCKET_NAME
```
